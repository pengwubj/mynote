# PTX 8.6/8.7

## New data format

### fp4/fp6 数据格式

+ 新增了 fp4/fp6 数据格式，遵循了 [OCP microscaling formats 规范](https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf)。至此，OCP 定义的所有 Element 类型在 blackwell 都做了支持。E 是 2/3/4 bit 的时候，为了防止动态范围过小, 将 Exponent 全 1 对应的指数用到了 norm 的表示范围里，只保留了一种 nan 的表示或者不保留 nan 的表示能力。
  + fp8 数据格式 ![[Pasted image 20250210181631.png]]
  + fp6 数据格式 ![[Pasted image 20250210181510.png]]
  + fp4 数据格式 ![[Pasted image 20250210181541.png]]

### MX-scale 数据格式

这是 OCP 定义的 MX 数据格式，本质就是一组 element 共享一个用于修正动态范围或者精度的 scale。scale 是 8bit。![[Pasted image 20250210181645.png]]

+ 新增了 ue8m0 作为 mx(microscaling) 格式中的 mx-scale 数据类型,支持 element 是 fp4/fp6/fp8; 0xff 代表 NAN，不支持 inf
+ 新增了 ue4m3 作为有效数据是 fp4 时可选的 mx-scale 数据类型。（ptx 层面称为 mxf4nvf4)。fp4 不光要做动态范围的分组缩放，也要做一定的精度的修正。 scale 的数据在 mma 指令中，存储在每个线程的寄存器中 (和稀疏矩阵的 selector 数据类似)，在 tcgen5.mma 中，存在 tensormemory 中。

## New Packed data format

### 增加 fp4/fp6/ue8m0 对应的 packed 格式

+ fp4x2 按照 8bit 数据存储；fp4x4 按照 16bit 存储；
+ fp6x2 按照 16bit 存储数据，每个 fp6 高位补零扩展成 8bit；fp6x4 按照 32bit 存储数据。
+ ue8m0x2 按照 16bit 存储数据。(ue4m3 就是 fp8,且符号位为 0)。

这里似乎 ptx 有点问题：fp4x4 要按照 b32 存储么？ 但是在 cvt 指令里，fp4x4 作为 dst 是用 b16 格式存储。  
![[Pasted image 20250210181708.png]]

### fp8 提供 x4 的 packed 格式

存储在一个 b32 的寄存器中。

## New conversion instructions

要是对新的数据格式，同时增加第五种 rounding mode，Stochastic rounding。  
目前 Nvidia GPU 对数值转换的支持长这样子，高亮的是支持 packed 类型，灰色的是表明用普通指令 prmt lop3 实现的，红色下划线表明是 blackwell 新增的格式.

![[Pasted image 20250210181727.png]]

对比下，mi300 的精度转化如下：  
![[Pasted image 20250210181737.png]]  
当然，虽然 4bit、8bit 定点转换到浮点，在之前的架构里其实需要多条指令 hack，但是在最近指令里，这方面仍然是缺失的，用 fp4、fp6、fp8 解决低精度的量化问题也许是主流方向。

### fp32 -> tf32 add when frand2

fp32 to tf32 frnd2+{.relu} 增加了可选的 satfinite 的支持

```plain
F2FP.SATFINITE.RELU.TF32.F32.PACK_B R9, R9 
```

rna 指令和之前一样, 在 sass 层面翻译成了多条指令，没有原生的 sass 支持。

```plain
     HFMA2 R9, -RZ, RZ, 0, 0.00048828125 ;   
     LDC.64 R2, c[0x0][0x380] ;            
     IMAD.WIDE R4, R7, 0x4, R4 ;           
     LDG.E R0, desc[UR4][R4.64] ;          
     IMAD.WIDE R2, R7, 0x4, R2 ;           
     FSETP.GEU.AND P0, PT, |R0|, +INF , PT ;   
@!P0 IMAD.IADD.U32 R0, R0, 0x1, R9 ;       
     LOP3.LUT R9, R0, 0xffffe000, RZ, 0xc0, !PT
     FSETP.GEU.AND P0, PT, |R9|, +INF , PT ;   
 @P0 IADD3 R9, PT, PT, R9, -0x2000, RZ ;   
```

### fp32 -> fp4x2

新增了 fp32 到 fp4x2 的转换指令.  
以下部分代码直接引用自 cutlass 中的特化

```
asm volatile( \
  "{\n" \
  ".reg .b8 byte0;\n" \
  ".reg .b8 byte1;\n" \
  "cvt.rn.satfinite.e2m1x2.f32   byte0, %2, %1;\n" \
  "cvt.rn.satfinite.e2m1x2.f32   byte1, %4, %3;\n" \
  "mov.b32 %0, {byte0, byte1, 0, 0};\n" \
  "}" \
  : "=r"(out) : "f"(source[0]), "f"(source[1]), "f"(source[2]), "f"(source[3]));

  F2FP.SATFINITE.E2M1.F32.PACK_AB_MERGE_C R6, R11, R6, RZ 
  F2FP.SATFINITE.E2M1.F32.PACK_AB_MERGE_C R0, R9, R0, R6 
```

```
asm volatile( \
    "{\n" \
    ".reg .b8 byte0;\n" \
    ".reg .b8 byte1;\n" \
    ".reg .b8 byte2;\n" \
    ".reg .b8 byte3;\n" \
    "cvt.rn.satfinite.e2m1x2.f32   byte0, %2, %1;\n" \
    "cvt.rn.satfinite.e2m1x2.f32   byte1, %4, %3;\n" \
    "cvt.rn.satfinite.e2m1x2.f32   byte2, %6, %5;\n" \
    "cvt.rn.satfinite.e2m1x2.f32   byte3, %8, %7;\n" \
    "mov.b32 %0, {byte0, byte1, byte2, byte3};\n" \
    "}" \
    : "=r"(b[tid]) : "f"(c[tid+0]), "f"(c[tid+1]), "f"(c[tid+2]), "f"(c[tid+3]),
                  "f"(c[tid+4]), "f"(c[tid+5]), "f"(c[tid+6]), "f"(c[tid+7]));

 F2FP.SATFINITE.E2M1.F32.PACK_AB_MERGE_C R10, R15, R10, RZ
 F2FP.SATFINITE.E2M1.F32.PACK_AB_MERGE_C R8, R13, R8, R10 
 F2FP.SATFINITE.E2M1.F32.PACK_AB_MERGE_C R6, R11, R6, R8 
 F2FP.SATFINITE.E2M1.F32.PACK_AB_MERGE_C R0, R9, R0, R6
```

### fp4x2 -> fp16x2

fp4x2 存在一个 8bit 格式中，sass 指令可以具备 input select 的能力，从 32bit 中选择 1 个 8bit 数据  
rounding mode 仅支持 rn, 不支持直接转成 fp32，需要额外的转换

```
    asm volatile( \
        "{\n" \
        ".reg .b8 byte0, byte1, byte2, byte3;\n" \
        "mov.b32 {byte0, byte1, byte2, byte3}, %4;\n" \
        "cvt.rn.f16x2.e2m1x2 %0, byte0;\n" \
        "cvt.rn.f16x2.e2m1x2 %1, byte1;\n" \
        "cvt.rn.f16x2.e2m1x2 %2, byte2;\n" \
        "cvt.rn.f16x2.e2m1x2 %3, byte3;\n" \
        "}\n" : "=r"(out_fp16[0]), "=r"(out_fp16[1]) , "=r"(out_fp16[2]), "=r"(out_fp16[3]): "r"(src_packed));

    float2 res0 = __half22float2(reinterpret_cast<__half2 &>(out_fp16[0]));
    float2 res1 = __half22float2(reinterpret_cast<__half2 &>(out_fp16[1]));
    float2 res2 = __half22float2(reinterpret_cast<__half2 &>(out_fp16[2]));
    float2 res3 = __half22float2(reinterpret_cast<__half2 &>(out_fp16[3]));

    result_type out;
    out[0] = res0.x;
    out[1] = res0.y;
    out[2] = res1.x;
    out[3] = res1.y;
    out[4] = res2.x;
    out[5] = res2.y;
    out[6] = res3.x;
    out[7] = res3.y;
    return out;
  
    F2FP.F16.E2M1.UNPACK_B R0, R2.reuse ;  
    F2FP.F16.E2M1.UNPACK_B R3, R2.B1 ;   
    HADD2.F32 R7, -RZ, R0.reuse.H0_H0 ;  
    HADD2.F32 R9, -RZ, R0.H1_H1 ;      
    F2FP.F16.E2M1.UNPACK_B R0, R2.reuse.B2 
    HADD2.F32 R11, -RZ, R3.reuse.H0_H0 ;   
    F2FP.F16.E2M1.UNPACK_B R2, R2.B3 ;   
    HADD2.F32 R3, -RZ, R3.H1_H1 ;      
    STG.E desc[UR4][R4.64], R7 ;       
    HADD2.F32 R13, -RZ, R0.reuse.H0_H0 ;   
    HADD2.F32 R15, -RZ, R0.H1_H1 ;     
    STG.E desc[UR4][R4.64+0x4], R9 ;   
    HADD2.F32 R17, -RZ, R2.H0_H0 ;     
    HADD2.F32 R19, -RZ, R2.H1_H1 ;
```

### fp32-> fp6x2

fp6 通过补 2 个 0 的方式，按照 8bit 存储，fp6x2 占 16bit；

```
    asm volatile( \
        "{\n" \
        ".reg .b16 lo;\n" \
        ".reg .b16 hi;\n" \
        "cvt.rn.satfinite.e2m3x2.f32   lo, %2, %1;\n" \
        "cvt.rn.satfinite.e2m3x2.f32   hi, %4, %3;\n" \
        "mov.b32 %0, {lo, hi};\n" \
        "}" \
        : "=r"(out) : "f"(source[0]), "f"(source[1]), "f"(source[2]), "f"(source[3]));

F2FP.SATFINITE.E2M3.F32.PACK_AB_MERGE_C R6, R11, R6, RZ 
F2FP.SATFINITE.E2M3.F32.PACK_AB_MERGE_C R9, R9, R0, R6 
```

### fp6x2 -> fp16

```
    asm volatile( \
        "{\n" \
        ".reg .b16 lo, hi;\n" \
        "mov.b32 {lo, hi}, %2;\n" \
        "cvt.rn.f16x2.e2m3x2 %0, lo;\n" \
        "cvt.rn.f16x2.e2m3x2 %1, hi;\n" \
        "}\n" : "=r"(out_fp16[0]), "=r"(out_fp16[1]) : "r"(src_packed));

F2FP.F16.E2M3.UNPACK_B R7, R4.reuse
F2FP.F16.E2M3.UNPACK_B R9, R4.H1 
```

同样具备 input select 的能力

支持的是 fp32 —>fp6/fp4 以及 fp6/fp4 -> f16x2 的转换。

### ue8m0x2

ue8m0 只能用 x2 的格式被使用。  
支持 fp32/bf16 —>ue8m0x2, 以及 bf16 —> ue8m0x2  
产生 ue8m0x2 不支持 rn，支持的是 rz 或者 rp；

```
    asm volatile( \
        "{\n" \
        ".reg .b16 lo;\n" \
        ".reg .b16 hi;\n" \
        "cvt.rp.satfinite.ue8m0x2.f32   lo, %2, %1;\n" \
        "cvt.rp.satfinite.ue8m0x2.f32   hi, %4, %3;\n" \
        "mov.b32 %0, {lo, hi};\n" \
        "}" \
        : "=r"(out) : "f"(source[0]), "f"(source[1]), "f"(source[2]), "f"(source[3]));

F2FP.SATFINITE.E8.F32.PACK_AB_MERGE_C.RP R6, R11, R6, RZ
F2FP.SATFINITE.E8.F32.PACK_AB_MERGE_C.RP R9, R9, R0, R6 
```

```
    asm volatile( \
        "{\n" \
        ".reg .b16 lo, hi;\n" \
        "mov.b32 {lo, hi}, %2;\n" \
        "cvt.rn.bf16x2.ue8m0x2 %0, lo;\n" \
        "cvt.rn.bf16x2.ue8m0x2 %1, hi;\n" \
        "}\n" : "=r"(out_fp16[0]), "=r"(out_fp16[1]) : "r"(src_packed));
      
F2FP.BF16.E8.UNPACK_B R7, R4.reuse
F2FP.BF16.E8.UNPACK_B R9, R4.H1
```

此外，在 ptx 中有这样的表述，但是实际 bf16x2 -> e8m0 并不支持 relu。  
![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/65817/1739155455368-c0ce2964-051f-4afe-9b39-e82c7e36ab9a.png)

### fp32 -> fp8x4 | fp6x4 | fp4x4 + .rs

**sm_100a 支持。** 用 rbits 存储伪随机数；提供有限宽度的随机数，rbit=16bit,  
每两个数复用一组 rbits。具体做法其实就是在做 rounding 的时候，在 mantissa 上加上 rbits。  
如果 rbits 小于实际的 mantissa source - mantissa target，就丢掉 source 上多出来的 bit。

对比 mi300 中的实现方式：用了 20b 和 21bit 的 rbit 实现 SR，但是对应的并行度只有 1. NV 通过降低 rbit 和  
共享 rbit，用 32bit 支持 4 路的 fp8 转化。

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/65817/1739158488261-bd46b8f5-d2ea-4aee-8ad5-6fd025b69699.png)

一些数据似乎表明较小的 rbit, 比如 8bit，也能解决问题,获得比 RN 更好的效果。  
![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/65817/1739155515952-26935b07-ecc0-45c5-9779-47b5a4d2a13a.png)

下面摘自 MI300 CDNA3 的指令集，介绍了两条 SR 的 CVT 指令义；

```
//V_CVT_SR_BF8_F32 677
prev_mode = ROUND_MODE;
ROUND_MODE = ROUND_NEAREST_EVEN;
s = sign(S0.f32);
e = exponent(S0.f32);
m = 23'U(32'U(23'B(mantissa(S0.f32))) + S1[31 : 11].u32);
tmp = float32(s, e, m);
// Add stochastic value to mantissa, wrap around on overflow
if OPSEL[3 : 2].u2 == 2'0U then
VGPR[laneId][VDST.u32][7 : 0].bf8 = f32_to_bf8(tmp.f32)
elsif OPSEL[3 : 2].u2 == 2'1U then
VGPR[laneId][VDST.u32][15 : 8].bf8 = f32_to_bf8(tmp.f32)
elsif OPSEL[3 : 2].u2 == 2'2U then
VGPR[laneId][VDST.u32][23 : 16].bf8 = f32_to_bf8(tmp.f32)
else
VGPR[laneId][VDST.u32][31 : 24].bf8 = f32_to_bf8(tmp.f32)
endif;
// Unwritten bytes of D are preserved.
ROUND_MODE = prev_mode

//V_CVT_SR_FP8_F32 676
prev_mode = ROUND_MODE;
ROUND_MODE = ROUND_NEAREST_EVEN;
s = sign(S0.f32);
e = exponent(S0.f32);
m = 23'U(32'U(23'B(mantissa(S0.f32))) + S1[31 : 12].u32);
tmp = float32(s, e, m);
// Add stochastic value to mantissa, wrap around on overflow
if OPSEL[3 : 2].u2 == 2'0U then
VGPR[laneId][VDST.u32][7 : 0].fp8 = f32_to_fp8(tmp.f32)
elsif OPSEL[3 : 2].u2 == 2'1U then
VGPR[laneId][VDST.u32][15 : 8].fp8 = f32_to_fp8(tmp.f32)
elsif OPSEL[3 : 2].u2 == 2'2U then
VGPR[laneId][VDST.u32][23 : 16].fp8 = f32_to_fp8(tmp.f32)
else
VGPR[laneId][VDST.u32][31 : 24].fp8 = f32_to_fp8(tmp.f32)
endif;
// Unwritten bytes of D are

```

此外, AMD 指令集提到：

> The VGPR holding the PRNG is not updated; the new pseudo-random value is created internally via  
> V_PRNG_B32 but not written

看起来是有一条指令产生伪随机数，但是并没有在指令集看到解释。也没有在 LLVM 文档找到这条指令：  
[https://llvm.org/docs/AMDGPU/AMDGPUAsmGFX940.html](https://llvm.org/docs/AMDGPU/AMDGPUAsmGFX940.html)

#### Tesla BFloat16/Float32 -> cfloat8 可以用 SR

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/65817/1739155548893-e67289f6-5c3e-4320-989d-7a7276864aa5.png)

#### AWS 从第二代 NeuronCore 开始支持 SR

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/65817/1739155563971-ae33ef07-88f6-42f8-bf7d-5b8d12e37f54.png)

#### Graphcore IPU

[https://docs.graphcore.ai/projects/ai-float-white-paper/en/latest/ai-float.html](https://docs.graphcore.ai/projects/ai-float-white-paper/en/latest/ai-float.html)

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/65817/1739162585437-96b2f3a3-f21c-4d57-aee0-5b52fed678f9.png)

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/65817/1739162501524-3614268f-2fc0-4529-bb96-5497f32e07d9.png)

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/65817/1739162773893-1a2adeec-8beb-4a65-a7e3-1f02089440de.png)

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/65817/1739163739586-ba7af2db-94f7-4ce6-9e3e-7d60cafda1f6.png)

### fp32 -> fp16x2 bf16x2 + .rs

**sm_100a**

fp16 m=10bit rbit = 23-10 = 13bit  
bf16 m=7bit rbit = 23 - 7 = 16bit  
x2 模式，一个 32bit rbits 放两个 rbits

### One more thing

Nvidia 的 convert 指令在 ptx 上基本没有暴露其具备 input selector 和 output merge+selector 的能力， 但是尽管有 pack 指令，也存在输出 32bit 寄存器 用不满的情况，这种情况，可以用多条 ptx，配合 mov 指令，将多个 b16 或者 b8 的结果拼接在一起，在 sass 层面，则用到了 MERGE_C 的能力，第一条指令 C 为 Zero，后面则 merge 上一条的输出寄存器。  
对于输入是 b16 或者 b8，则可以用 B0、B1、B2、B3 或者 H0、H1 来做数据选择。上面的 sass 指令在这两种情况都有所体现。因此可以不借助移位指令完成输入的选择和输出的拼接。

## New f32x2 add/sub/mul/fma

新增了 fp32x2 的向量化浮点乘加指令，一条指令完成两组 f32 的乘加计算。

如果其中一个操作数两路向量共用的，sass 层面不用讲这个 32bit 数据复制两份，而是直接用一个 b32 的寄存器即可。这一点没有在 ptx 暴露。

```
asm volatile( \
        "{\n" \
        ".reg .b64 test1;\n" \
        ".reg .b64 test2;\n" \
        "mov.b64 test2, {%5,%4};\n" \
        "mov.b64 test1, {%5,%5};\n" \
        "fma.rn.ftz.f32x2 %0, test1, %2,test2;\n" \
        "}\n" : "=l"(out[tid+0]) : "l"(src[tid+0]) , "l"(src[tid+1]) , "l"(src[tid+2]),"r"(src32[tid]),"r"(src32[tid+1]));
      
FFMA2.FTZ R4, R10.F32, R4.F32x2.HI_LO, R10.F32x2.HI_LO
```

cutlass 封装了这些 ptx [cutlas 封装](https://github.com/NVIDIA/cutlass/blob/affd1b693dfc121c51118cbc8583dfd308227ca6/include/cute/arch/simd_sm100.hpp)

这条指令和 AMD CDNA2(MI200 系列) 增加的 FP32 Packed Math 指令一致。

```cpp
V_PK_FMA_F32
V_PK_MUL_F32
V_PK_ADD_F32
V_PK_MOV_B32
```

为啥需要这样的指令？ [留给自己的问题，要做一些实验看看]  
对于 NV  
h100 是增加了一个独立的 pipe 来出来增加的 16 的 fp32 alu， 所以隐含要用两个 warp 的 fma 指令才能打满，blackwell 通过这条指令取消了这个限制？那么用普通的 fp32+ 多个 warp，还能打满 fp32 alu 么？ 同时利用 register even align 的特性，可以无冲突的读出 vec2 的数据，性能更容易得到保障？而且 nv 没有强调要用 packed 指令才能打满性能，如果是 amd 那种倍数关系，应当 highlight。

对于 AMD MI200  
还是因为发射限制，不采用 packed 指令就无法一周期发射足够的并行度指令给 alu， 因为 CDNA2 如果不用 packed fp32, 则只有 64fp32/CU 可以用。应该是直接把 16 个并行度的 FP ALU 支持了 double 精度，同时一个 double 可以做两路 single。 但是整体架构限制每个周期不能丢出来两个相同 pipe 的指令，用两个 fp32 fma 一起打满它，只有用 packed 指令复用了 double 的发射通路才可以做到。

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/65817/1739155596409-79450c50-0a0b-4362-ad1f-30747f3d6aea.png)

## New Mixed precision add/sub/fma

```cpp
d = convert(a) + c;
d = convert(a) - c;
d = convert(a) * convert(b) + c;
```

方便用高精度累加，避免精度丢失停滞。节省了一次 convert 的时间。但是问题是，这里的只支持一路 fp16，通常 fp16x2（__half2） 存在一个 32bit register 中，尝试写一个带 mov 指令的 ptx，发现 sass 层面对这个 16bit 输入的数据也是有选择 HI/LOW 的能力

```
asm volatile( \
        "{\n" \
        ".reg .b16 lo;\n" \
        ".reg .b16 hi;\n" \
        "mov.b32 {lo, hi}, %3;\n" \
        "add.rz.f32.bf16.sat  %0, hi, %2;\n" \
        "add.rz.f32.bf16.sat  %1, lo, %2;\n" \
        "}" \
        : "=f"(out[tid]), "=f"(out[tid+1]) : "f"(src_f[tid+0]), "r"(src_i[tid+0]));

FHADD.BF16.RZ.SAT R9, R7.reuse.H1, R4.reuse ; 
FHADD.BF16.RZ.SAT R11, R7, R4 ; 
```

## New float support in redux.sync

新增 float min/max reduce 指令

```plain
redux.sync.op{.abs.}{.NaN}.f32 dst, src, membermask 
.op   = { .min, .max }
```

.NaN 的能力和 float min/max 中的.NaN 含义一致。浮点比较可以复用定点比较的逻辑，可以参考 radix sort 处理 float 输入的逻辑，额外处理下 Nan 值就好，增加了 f32 min、max 硬件开销非常少。对比下 float reduce sum 则需要增加更多的资源，并没有支持。浮点 reduce max 的引入，可以用在 softmax 查找最大值，以及 online 的低精度量化。毕竟之前的 warp reduce 要用 5 个 shuffle 和 5 个 float max 来完成，现在只需要一条指令。cutlass 中也对这个 reduce 做了封装，注意封装的版本的带.NaN 和.abs 的版本，用于寻找最大值做低精度量化使用。  
reduce 的结果直接广播给每个线程，传统做法最后只有一个线程包含有效的结果，需要额外结果 shuffle 广播给每个线程。

```
struct redux_abs_max_nan_propagation_sync_warp <float>{
  CUTLASS_DEVICE
  float operator()(float const &lhs) const {
#if defined(CUTLASS_ARCH_CREDUX_ENABLED)
    float result;
    asm volatile("redux.sync.max.abs.NaN.f32 %0, %1, 0xffffffff;\n" : "=f"(result) : "f"(lhs));
    return result;
#elif defined(__CUDA_ARCH__)
    cutlass::maximum<float, /*PropagateNaN*/true> max_op;
    int shuffle_width = 32;
    float abs_max = cutlass::absolute_value_op<float>{}(lhs);
    CUTLASS_PRAGMA_UNROLL
    for(int offset = shuffle_width / 2; offset > 0; offset /= 2) {
      float value = __shfl_down_sync(0xffffffff, abs_max, offset, shuffle_width);
      abs_max = max_op(abs_max,value);
    }
    // Broadcast the maximum to all threads participating in the reduction.
    abs_max = __shfl_sync(0xffffffff, abs_max, 0, shuffle_width);
    return abs_max;
#else
    CUTLASS_UNUSED(lhs);
    CUTLASS_NOT_IMPLEMENTED();
    return 0;
#endif
  }
};
```

## New MMA in sm_120a

### 混合低精度模式

m16n8k32, row_col, a/b=f4/f6/f8 支持 a/b 不同精度,** c=f16/f32**

fp4/fp6 也需要通过 padding 的方式占用 8bit，fp4 在这种模式下应该只能做到 f8 的算力。 f6 本身算力就和 f8 一样（不同于 AMD）。 a/b 的 layout 也和 f8 一样，占用 4 个寄存器。在外存和 sharemem 存储依然可以用 non-padding 的方式，发挥低精度的优势，而且支持混合精度，避免了一次额外的精度转换, 硬件处理的时候复用了 fp8 的数据和计算通路。

![[Pasted image 20250210181957.png]]

### 混合低精度模式 + mx-black scaling

m16n8k32, row_col, a/b=f4/f6/f8, **c=f32**, scale:ue8m0

scale_vec: x1 也就是 k 上 32 个数共一个 scale (和 OCP 定义一致)

固定需要提供 16 个 A scale 和 8 个 B scale。每个线程 4Byte，共 128Byte 可以提供 8 组 A scale 和 16 组 B scale， 用对应单位 selector 来进行选择；和 sparse 的控制机制一样，保证了这些 meta data 可以用密集的存储在 memory 和寄存器中，降低寄存器占用，保证数据搬运。

byte-id 选择每个线程 4byte 中使用哪个 byte；

thread-id 选择每次用哪些 lane 提供的 4byte；

![[Pasted image 20250210181949.png]]

![[Pasted image 20250210181938.png]]

### fp4 高性能 + mx-black scaling

m16n8k64 row_col ** a/b=f4** **scale:ue8m0**，**c=f32** 仅支持 f4，a/b 中的 fp4 不需要 padding 到 8bit；

scale_vec: x2 k 增加一倍，对应的 scale_vec 的需求也 x2 , 保持 OCP 32 个；element 共享 scale；每次 mma 从每个线程的 4byte 选 2 个 byte。

![[Pasted image 20250210181926.png]]

### fp4 高性能 + nv-black scaling（mxf4nvf4）

m16n8k64 row_col a/b=f4 c=f32 **scale:ue4m3 scale_vec x4**

不在是 OCP 定义的 scale 格式，可以支持 16 个 k 维度的数据共享一个 scale（x4 模式），选中的线程的 4byte 都会备用到，byte-select 不用再选了。scale 也增加了一种新的格式， ue4m3 , 无符号的 fp8，所以不用像 ue8m0 一样单独设计 cvt 指令，直接 abs 就好了。同 fp8 的 e4m3 一样，用 0x7f 做唯一 nan，剩下的都用来表达数据。

## New ldmatrix sm_10xa sm_120a

### ldmatrix.sync.aligned.shape.num.type r, [p]

8bit 16x16 x1/x2 可以 trans

### ldmatrix.sync.aligned.m8n16.num.dst_fmt.src_fmt r, [p]

不支持转置，和 shm-> tensormem 的解压缩逻辑一样，支持 4bit 6bit 在 shm 里连续存放，读取 16 个 4bit 或者 6bit，之后每个元素 padding 到 8bit，存入寄存器中，连续 4 个 lane 共 128bit。这个格式对应到 mma 的输入格式。因此可以在内存里继续用压缩格式存储。支持 x1 x2 x4;

![[Pasted image 20250210181909.png]]

### ldmatrix.sync.aligned.m16n16.num.trans.dst_fmt.src_fmt r, [p]

转置版本，必须是方矩阵。支持 x1 x2。【新】

![[Pasted image 20250210181859.png]]

## New stmatrix sm_10xa sm_120a

### stmatrix.sync.aligned.m16n8.num.trans.b8 [p], r

16x8 的 8bit 转置写入 sharedmem；

这里可以看出来 stmatrix 的 rowx，col0-3 不是存在一个寄存器里，和 ldmatrix 其实 layout 是不兼容，也就是说直接用 ldmatrix.trans 加载上来，在用 stmatrix,trans 写回去，是得不到原始的矩阵的。。。。

这就是 cutlass 在封装的时候，做了 byte permute 的原因。但是这不重要，因为 stmatrix 匹配的是 mma 的输出格式，ldmatrix 匹配的是 mma 输入的格式。

mma 的 C/D 矩阵，T0 存储的数据是 r0c0,r0c1,r8c0,r8c1 输出的 fp32 或者 fp16 cvt 成 fp8 后，正好对应到 stmatrix 的 register 排布方式。如果输出直接是 fp16， 也可以 map stmatrix.b16 的格式。换句话说，fp16 的输出是可以直接做 mma 的输入。  
![[Pasted image 20250210181847.png]]![[Pasted image 20250210181839.png]]
